{"ast":null,"code":"module.exports =\n/*#__PURE__*/\nfunction () {\n  function RateLimitedQueue(limit) {\n    if (typeof limit !== 'number' || limit === 0) {\n      this.limit = Infinity;\n    } else {\n      this.limit = limit;\n    }\n\n    this.activeRequests = 0;\n    this.queuedHandlers = [];\n  }\n\n  var _proto = RateLimitedQueue.prototype;\n\n  _proto._call = function _call(fn) {\n    var _this = this;\n\n    this.activeRequests += 1;\n    var _done = false;\n    var cancelActive;\n\n    try {\n      cancelActive = fn();\n    } catch (err) {\n      this.activeRequests -= 1;\n      throw err;\n    }\n\n    return {\n      abort: function abort() {\n        if (_done) return;\n        _done = true;\n        _this.activeRequests -= 1;\n        cancelActive();\n\n        _this._queueNext();\n      },\n      done: function done() {\n        if (_done) return;\n        _done = true;\n        _this.activeRequests -= 1;\n\n        _this._queueNext();\n      }\n    };\n  };\n\n  _proto._queueNext = function _queueNext() {\n    var _this2 = this; // Do it soon but not immediately, this allows clearing out the entire queue synchronously\n    // one by one without continuously _advancing_ it (and starting new tasks before immediately\n    // aborting them)\n\n\n    Promise.resolve().then(function () {\n      _this2._next();\n    });\n  };\n\n  _proto._next = function _next() {\n    if (this.activeRequests >= this.limit) {\n      return;\n    }\n\n    if (this.queuedHandlers.length === 0) {\n      return;\n    } // Dispatch the next request, and update the abort/done handlers\n    // so that cancelling it does the Right Thing (and doesn't just try\n    // to dequeue an already-running request).\n\n\n    var next = this.queuedHandlers.shift();\n\n    var handler = this._call(next.fn);\n\n    next.abort = handler.abort;\n    next.done = handler.done;\n  };\n\n  _proto._queue = function _queue(fn) {\n    var _this3 = this;\n\n    var handler = {\n      fn: fn,\n      abort: function abort() {\n        _this3._dequeue(handler);\n      },\n      done: function done() {\n        throw new Error('Cannot mark a queued request as done: this indicates a bug');\n      }\n    };\n    this.queuedHandlers.push(handler);\n    return handler;\n  };\n\n  _proto._dequeue = function _dequeue(handler) {\n    var index = this.queuedHandlers.indexOf(handler);\n\n    if (index !== -1) {\n      this.queuedHandlers.splice(index, 1);\n    }\n  };\n\n  _proto.run = function run(fn) {\n    if (this.activeRequests < this.limit) {\n      return this._call(fn);\n    }\n\n    return this._queue(fn);\n  };\n\n  _proto.wrapPromiseFunction = function wrapPromiseFunction(fn) {\n    var _this4 = this;\n\n    return function () {\n      for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n        args[_key] = arguments[_key];\n      }\n\n      return new Promise(function (resolve, reject) {\n        var queuedRequest = _this4.run(function () {\n          var cancelError;\n          fn.apply(void 0, args).then(function (result) {\n            if (cancelError) {\n              reject(cancelError);\n            } else {\n              queuedRequest.done();\n              resolve(result);\n            }\n          }, function (err) {\n            if (cancelError) {\n              reject(cancelError);\n            } else {\n              queuedRequest.done();\n              reject(err);\n            }\n          });\n          return function () {\n            cancelError = new Error('Cancelled');\n          };\n        });\n      });\n    };\n  };\n\n  return RateLimitedQueue;\n}();","map":null,"metadata":{},"sourceType":"script"}